# Keyword Speech Indexing â€” Full Stack (Python + Vanilla Frontend)

 Project to upload an audio/video file, generate subtitles (VTT) in **multiple Indian languages**, play the video with selectable subtitles, and **jump to timestamps by keyword**.


## Features

- ðŸ—‚ï¸ Upload audio/video
- ðŸ“ Transcribe with [OpenAI Whisper](local) â€” choose model via `WHISPER_MODEL` env var
- ðŸŒ Auto-translate subtitles to 11 Indian languages (via `deep-translator` GoogleTranslate backend)
- ðŸ“„ Save per-language `.vtt` files
- ðŸŽ¯ Keyword search: type a word, jump to its earliest occurrence, see all hits as clickable chips
- ðŸ§© Clean API (FastAPI) + static frontend
- ðŸ” CORS enabled for local dev
- ðŸ”Ž Simple VTT parser & word indexer

## Tech

- **Backend:** Python 3.9+, FastAPI, Uvicorn
- **ASR:** `openai-whisper` (requires `ffmpeg` installed on your system)
- **Translate:** `deep-translator` (uses Google Translate unofficially)
- **Frontend:** Plain HTML/CSS/JS (no build step)

## Setup

1. **Install system dependency**
   - **ffmpeg**:  
     - Windows: get a static build from ffmpeg.org and add `bin` to PATH  
     - macOS: `brew install ffmpeg`  
     - Linux (Debian/Ubuntu): `sudo apt-get install ffmpeg`

2. **Create & activate venv (recommended)**
   ```bash
   python -m venv .venv
   # Windows
   .venv\Scripts\activate
   # macOS/Linux
   source .venv/bin/activate
   ```

3. **Install Python deps**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the backend (dev)**
   ```bash
   uvicorn app.main:app --reload
   ```

5. **Open the frontend**
   - Navigate to: `http://127.0.0.1:8000/static/index.html`

## Usage

- Click **Upload & Transcribe**, pick your file.  
- Wait for processing (longer videos take longer).  
- Once ready, the video appears with track(s) for `en` and selected Indian languages.  
- Use the **keyword search** box: type a word (in the same script as the subtitle language), click **Go to first match**, and the player jumps to the first hit. All matches are shown as time chipsâ€”click any to jump.

## Notes & Tips

- First run downloads a Whisper model (default `small`). For faster/better accuracy, set env var `WHISPER_MODEL` to one of: `tiny`, `base`, `small`, `medium`, `large`.
- Translation uses `deep-translator`. If translation fails or rate-limits, the English transcript is used as a fallback for that language.
- Generated files are in `data/uploads/` (media) and `data/vtts/` (captions & indexes).
- API quick test:
  ```bash
  curl -F "file=@/path/to/video.mp4" "http://127.0.0.1:8000/api/upload?langs=en,hi,ta"
  curl "http://127.0.0.1:8000/api/search?video_id=abcd1234&lang=hi&q=à¤¨à¤®à¤¸à¥à¤¤à¥‡"
  ```

## File Tree

```
keyword-speech-indexing-fullstack/
â”œâ”€ app/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ main.py                # FastAPI app, upload+search endpoints, serves static & VTTs
â”‚  â”œâ”€ transcribe.py          # Whisper transcription + translation + VTT writer
â”‚  â”œâ”€ vtt_utils.py           # Minimal VTT parser
â”‚  â””â”€ search_index.py        # Builds/loads word->timestamps index per language
â”œâ”€ data/
â”‚  â”œâ”€ uploads/               # Saved media files
â”‚  â””â”€ vtts/                  # Generated VTTs + indexes
â”œâ”€ frontend/
â”‚  â”œâ”€ index.html
â”‚  â”œâ”€ styles.css
â”‚  â””â”€ script.js
â”œâ”€ requirements.txt
â”œâ”€ README.md
â”œâ”€ run_dev.sh
â””â”€ run_dev.bat
```

## Environment Variables

- `WHISPER_MODEL` â€” set to `tiny|base|small|medium|large` (default `small`)

## Windows / macOS helpers

- **Windows:** double-click `run_dev.bat` after installing dependencies.
- **macOS/Linux:** `bash run_dev.sh`

## Troubleshooting

- `ffmpeg not found` â†’ Install FFmpeg and ensure it is on your PATH.
- `CUDA not available` â†’ Whisper will fall back to CPU. For GPU, install PyTorch with CUDA.
- Translations missing â†’ ensure internet access; `pip install deep-translator`.
- If your video language is not English, Whisper still transcribes in the original language. The search works on the chosen subtitle language (word must match script/casing).

## License

MIT â€” use freely in your capstone with attribution.

## author
{ Bindu (https://github.com/Bindugowda2004)}
